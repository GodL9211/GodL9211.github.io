import{_ as p}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as i,c,a as n,b as s,e as t,f as e}from"./app-9976b6d0.js";const l="/assets/640-ed8c821a.webp",u="/assets/641-e43e291d.webp",r="/assets/642-4853e2cf.webp",d="/assets/642_demo-823841a1.webp",k="/assets/643-ebea5c92.webp",m="/assets/644-949ec0e9.webp",v="/assets/645-2476aa57.webp",b="/assets/646-88cccf2b.webp",g="/assets/647-611b0794.webp",y="/assets/648-8d3ea4a9.webp",h="/assets/651-a4d59f35.webp",f="/assets/652-b68504f1.webp",_="/assets/653-1badb1a0.webp",x="/assets/654-80327b32.webp",q="/assets/655-57f3047d.webp",w={},S=e('<h2 id="前言" tabindex="-1"><a class="header-anchor" href="#前言" aria-hidden="true">#</a> 前言</h2><p>大家好，我是海鸽。</p><h2 id="scrapy-简介" tabindex="-1"><a class="header-anchor" href="#scrapy-简介" aria-hidden="true">#</a> Scrapy 简介</h2><p>Scrapy 是一个用于爬取网站并提取结构化数据的强大且灵活的开源框架。它提供了简单易用的工具和组件，使开发者能够定义爬虫、调度请求、处理响应并存储提取的数据。Scrapy 具有高效的异步处理能力，支持分布式爬取，通过其中间件和扩展机制可以方便地定制和扩展功能，广泛应用于数据挖掘、信息聚合和自动化测试等领域。</p><figure><img src="'+l+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><ul><li><p><code>Scrapy Engine(引擎)</code>: 负责<code>Spider</code>、<code>ItemPipeline</code>、<code>Downloader</code>、<code>Scheduler</code>中间的通讯，信号、数据传递等。</p></li><li><p><code>Scheduler(调度器)</code>: 它负责接受<code>引擎</code>发送过来的Request请求，并按照一定的方式进行整理排列，入队，当<code>引擎</code>需要时，交还给<code>引擎</code>。</p></li><li><p><code>Downloader（下载器）</code>：负责下载<code>Scrapy Engine(引擎)</code>发送的所有Requests请求，并将其获取到的Responses交还给<code>Scrapy Engine(引擎)</code>，由<code>引擎</code>交给<code>Spider</code>来处理，</p></li><li><p><code>Spider（爬虫）</code>：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给<code>引擎</code>，再次进入<code>Scheduler(调度器)</code>，</p></li><li><p><code>Item Pipeline(管道)</code>：它负责处理<code>Spider</code>中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方.</p></li><li><p><code>Downloader Middlewares（下载中间件）</code>：你可以当作是一个可以自定义扩展下载功能的组件。</p></li><li><p><code>Spider Middlewares（Spider中间件）</code>：你可以理解为是一个可以自定扩展和操作<code>引擎</code>和<code>Spider</code>中间<code>通信</code>的功能组件（比如进入<code>Spider</code>的Responses;和从<code>Spider</code>出去的Requests）</p><hr></li></ul><p>1、启动爬虫：Scrapy 启动并激活爬虫，从初始 URL 开始爬取；</p><p>2、调度请求：爬虫生成初始请求，并将其发送给调度器；</p><p>3、下载页面：调度器将请求发送给下载器，下载器从互联网获取页面；</p><p>4、处理响应：下载器将响应返回给引擎，传递给爬虫；</p><p>5、提取数据：爬虫从响应中提取数据（items）和更多的 URL（新的请求）；</p><p>6、处理数据：提取的数据通过项目管道进行处理，清洗并存储；</p><p>7、继续爬取：新的请求被调度器处理，继续下载和提取数据，直到所有请求处理完毕。</p><figure><img src="'+u+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="安装-scrapy" tabindex="-1"><a class="header-anchor" href="#安装-scrapy" aria-hidden="true">#</a> 安装 Scrapy</h2><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>pip install scrapy
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>安装成功后，直接在命令终端输入 scrapy ，输出内容如下：</p><figure><img src="`+r+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="新建-scrapy-项目" tabindex="-1"><a class="header-anchor" href="#新建-scrapy-项目" aria-hidden="true">#</a> 新建 Scrapy 项目</h2><p>使用 <code>scrapy startproject + 项目名</code> 创建新项目。</p><p>这里我们使用 <code>scrapy startproject scrapy_demo</code> 创建项目示例：</p><figure><img src="'+d+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>然后通过下面命令创建我们的爬虫模板，这里就按照 Scrapy 给出的实例创建：</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>cd scrapy_demoscrapy genspider example example.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>使用 Pycharm 打开我们的项目，项目格式如下：</p><figure><img src="`+k+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>各个文件夹的含义：</p><ul><li>spiders：存放爬虫文件；</li><li>items：定义爬取的数据结构；</li><li>middlewares：定义下载中间件和爬虫中间件，中间件是处理请求和响应的钩子，可以修改请求、响应、异常等；</li><li>pipelines：定义管道，用于处理爬虫提取的数据，例如数据清洗、验证和存储等操作；</li><li>settings：定义了项目的基本配置。</li></ul><h2 id="使用-scrapy" tabindex="-1"><a class="header-anchor" href="#使用-scrapy" aria-hidden="true">#</a> 使用 Scrapy</h2><p>这里以我们熟悉的 <code>某瓣</code> 为例来说明 <code>scrapy</code> 的用法。</p>',30),E={href:"http://example.py",target:"_blank",rel:"noopener noreferrer"},R=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">ExampleSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&quot;example&quot;</span>
    <span class="token comment"># allowed_domains = [&quot;example.com&quot;]   # 允许爬取的网站范围，可以不要</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;https://movie.douban.com/top250&quot;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在终端输入 <code>scrapy crawl example</code> 运行结果如下：</p><figure><img src="`+m+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>输出了很多信息，包含版本号、插件、启用的中间件等信息：</p><ul><li>Versions：版本信息,包括 Scrapy 和其它库的版本信息；</li><li>Overridden settings：重写的相关配置；</li><li>Enabled downloader middlewares：开启的下载器中间件；</li><li>Enabled spider middlewares：开启的爬虫中间件；</li><li>Enabled item pipelines：开启的管道；</li><li>Telnet Password：Telnet 平台密码（Scrapy 附带一个内置的 telnet 控制台，用于检查和控制 Scrapy 运行过程）；</li><li>Enabled extensions ：开启的拓展功能；</li><li>Dumping Scrapy stats：所以的信息汇总。</li></ul><p>我们重点看这里：</p><figure><img src="'+v+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>可以发现，我们返回了 403 状态码，原因是因为我们少了请求头并遵循了 robots 协议。</p>',8),T={href:"http://setting.py",target:"_blank",rel:"noopener noreferrer"},I=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># Obey robots.txt rules</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>   <span class="token comment"># 这里改成 False，表示不遵守 robots 协议</span>

<span class="token comment"># Override the default request headers:</span>
DEFAULT_REQUEST_HEADERS <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">&quot;Accept&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;Accept-Language&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;en&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;User-Agent&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0&quot;</span>
<span class="token punctuation">}</span>  <span class="token comment"># 然后把这个放开，这个表示该项目的默认请求头</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>运行之后，可以发现能正常返回 html 页面数据。</p><h3 id="scrapy-运行项目的两种方式" tabindex="-1"><a class="header-anchor" href="#scrapy-运行项目的两种方式" aria-hidden="true">#</a> <strong>Scrapy 运行项目的两种方式</strong></h3><p>上面我们是通过终端运行的，下面我们使用 python 运行。</p>`,4),L={href:"http://example.py",target:"_blank",rel:"noopener noreferrer"},D=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline


<span class="token keyword">class</span> <span class="token class-name">ExampleSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&quot;example&quot;</span>
    <span class="token comment"># allowed_domains = [&quot;example.com&quot;]   # 允许爬取的网站范围，可以不要</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;https://movie.douban.com/top250&quot;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&#39;__main__&#39;</span><span class="token punctuation">:</span>
    cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;scrapy crawl example&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># cmdline.execute(&quot;scrapy crawl example --nolog&quot;.split()) 不输出提示信息</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果不想输出与爬虫无关的信息，可以在后面加上 --nolog 命令，这样就不会打印提示信息了。</p><h3 id="数据翻页抓取" tabindex="-1"><a class="header-anchor" href="#数据翻页抓取" aria-hidden="true">#</a> <strong>数据翻页抓取</strong></h3><p>scrapy 实现翻页请求，可以直接利用 scrapy 内置的数据解析方法对数据进行抓取。</p><p>代码如下：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline


<span class="token keyword">class</span> <span class="token class-name">ExampleSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&quot;example&quot;</span>
    <span class="token comment"># allowed_domains = [&quot;example.com&quot;]   # 允许爬取的网站范围，可以不要</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;https://movie.douban.com/top250&quot;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
        ol_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;//ol[@class=&quot;grid_view&quot;]/li&#39;</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> ol <span class="token keyword">in</span> ol_list<span class="token punctuation">:</span>
            item <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            <span class="token comment"># 利用scrapy封装好的xpath选择器定位元素，并通过extract()或extract_first()来获取结果</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;title&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;hd&quot;]/a/span[1]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;rating&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;bd&quot;]/div/span[2]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;quote&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;bd&quot;]//p[@class=&quot;quote&quot;]/span/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&#39;__main__&#39;</span><span class="token punctuation">:</span>
    cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;scrapy crawl example --nolog&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># cmdline.execute(&quot;scrapy crawl example&quot;.split())</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>上面只抓取到了第一页，那么我们怎么抓取后面的每一页呢？</p><p>这里介绍两种方式：</p><p>1、利用 callback 参数，进入项目源码，找到 Request 请求对象：</p><figure><img src="`+b+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>Request 对象含义如下：</p><table><thead><tr><th style="text-align:left;">参数</th><th style="text-align:left;">描述</th></tr></thead><tbody><tr><td style="text-align:left;">url (str)</td><td style="text-align:left;">请求的 URL。</td></tr><tr><td style="text-align:left;">callback (callable)</td><td style="text-align:left;">用于处理该请求的回调函数。默认是 <code>parse</code> 方法。</td></tr><tr><td style="text-align:left;">method (str)</td><td style="text-align:left;">HTTP 请求方法，如 <code>&#39;GET&#39;</code>, <code>&#39;POST&#39;</code> 等。默认为 <code>&#39;GET&#39;</code>。</td></tr><tr><td style="text-align:left;">headers (dict)</td><td style="text-align:left;">请求头信息。</td></tr><tr><td style="text-align:left;">body (bytes or str)</td><td style="text-align:left;">请求体，通常在 POST 请求中使用。</td></tr><tr><td style="text-align:left;">cookies (dict or list)</td><td style="text-align:left;">请求携带的 Cookies，可以是一个字典或字典的列表。</td></tr><tr><td style="text-align:left;">meta (dict)</td><td style="text-align:left;">该请求的元数据字典，用于在不同请求之间传递数据。</td></tr><tr><td style="text-align:left;">encoding (str)</td><td style="text-align:left;">请求的编码格式。默认为 <code>&#39;utf-8&#39;</code>。</td></tr><tr><td style="text-align:left;">priority (int)</td><td style="text-align:left;">请求的优先级，默认值为 0。优先级值越高，优先级越高。</td></tr></tbody></table><p>callback 就是回调函数，接收一个函数名为参数。</p><p>实现如下：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
    ol_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;//ol[@class=&quot;grid_view&quot;]/li&#39;</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> ol <span class="token keyword">in</span> ol_list<span class="token punctuation">:</span>
        item <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token comment"># extract_first() 提取第一个元素</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;title&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;hd&quot;]/a/span[1]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;rating&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;bd&quot;]/div/span[2]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">&#39;quote&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;bd&quot;]//p[@class=&quot;quote&quot;]/span/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">if</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//a[text()=&#39;后页&gt;&#39;]/@href&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            next_url <span class="token operator">=</span> response<span class="token punctuation">.</span>urljoin<span class="token punctuation">(</span>response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&quot;//a[text()=&#39;后页&gt;&#39;]/@href&quot;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>next_url<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>next_url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>2、重写 start_requests 方法：</p><figure><img src="`+g+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            url <span class="token operator">=</span> <span class="token string">&#39;https://movie.douban.com/top250?start={}&amp;filter=&#39;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i <span class="token operator">*</span> <span class="token number">25</span><span class="token punctuation">)</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ol_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;//ol[@class=&quot;grid_view&quot;]/li&#39;</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> ol <span class="token keyword">in</span> ol_list<span class="token punctuation">:</span>
            item <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            <span class="token comment"># extract_first() 提取第一个元素</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;title&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;hd&quot;]/a/span[1]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;rating&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;bd&quot;]/div/span[2]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;quote&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;bd&quot;]//p[@class=&quot;quote&quot;]/span/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Responses 对象含义如下：</p><table><thead><tr><th style="text-align:left;">参数</th><th style="text-align:left;">描述</th></tr></thead><tbody><tr><td style="text-align:left;">url (str)</td><td style="text-align:left;">响应的 URL。</td></tr><tr><td style="text-align:left;">status (int)</td><td style="text-align:left;">HTTP 响应状态码。</td></tr><tr><td style="text-align:left;">headers (dict)</td><td style="text-align:left;">响应头信息。</td></tr><tr><td style="text-align:left;">body (bytes)</td><td style="text-align:left;">响应体内容，二进制格式。</td></tr><tr><td style="text-align:left;">flags (list)</td><td style="text-align:left;">响应的标志列表。</td></tr><tr><td style="text-align:left;">request (Request)</td><td style="text-align:left;">生成此响应的请求对象。</td></tr><tr><td style="text-align:left;">meta (dict)</td><td style="text-align:left;">该请求的元数据字典，用于在不同请求之间传递数据。</td></tr><tr><td style="text-align:left;">encoding (str)</td><td style="text-align:left;">响应的编码格式。通常由 Scrapy 自动检测，但可以手动设置。</td></tr><tr><td style="text-align:left;">text (str)</td><td style="text-align:left;">响应体内容，解码为字符串格式。</td></tr><tr><td style="text-align:left;">css (callable)</td><td style="text-align:left;">选择器，用于通过 CSS 表达式提取数据。</td></tr><tr><td style="text-align:left;">xpath (callable)</td><td style="text-align:left;">选择器，用于通过 XPath 表达式提取数据。</td></tr><tr><td style="text-align:left;">json (callable)</td><td style="text-align:left;">解析 JSON 响应体并返回字典或列表。</td></tr></tbody></table><h2 id="数据定义" tabindex="-1"><a class="header-anchor" href="#数据定义" aria-hidden="true">#</a> 数据定义</h2><p>数据爬取下来之后，我们通过 scrapy 的 items 进行操作。item 就是即提前规划好哪些字段需要抓取，比如上面的标题、评分这些字段就需要使用 item 提前定义好。</p><h3 id="scrapy-item-的作用" tabindex="-1"><a class="header-anchor" href="#scrapy-item-的作用" aria-hidden="true">#</a> <strong>Scrapy Item 的作用</strong></h3><ol><li><strong>结构化数据</strong>：通过定义 Item，可以明确抓取数据的结构。例如，一个商品的信息可能包含名称、价格、库存等字段；</li><li><strong>数据验证</strong>：可以在 Item 中定义字段的类型和验证规则，确保抓取的数据符合预期；</li><li><strong>代码可读性</strong>：通过定义 Item，可以使代码更具可读性和可维护性，清晰地了解抓取的数据结构。</li></ol><h3 id="定义-item" tabindex="-1"><a class="header-anchor" href="#定义-item" aria-hidden="true">#</a> <strong>定义 item</strong></h3>`,25),P={href:"http://item.py",target:"_blank",rel:"noopener noreferrer"},A=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">ScrapyDemoItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    <span class="token comment"># name = scrapy.Field()</span>
    title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    rating <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    quote <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="使用-item" tabindex="-1"><a class="header-anchor" href="#使用-item" aria-hidden="true">#</a> <strong>使用 item</strong></h3><p>使用 item 需要先实例化，使用方法和 python 字典方式一样。</p>`,3),N={href:"http://example.py",target:"_blank",rel:"noopener noreferrer"},M=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy  
<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline
<span class="token keyword">from</span> scrapy_demo<span class="token punctuation">.</span>items <span class="token keyword">import</span> ScrapyDemoItem

<span class="token keyword">class</span> <span class="token class-name">ExampleSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&quot;example&quot;</span>

    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            url <span class="token operator">=</span> <span class="token string">&#39;https://movie.douban.com/top250?start={}&amp;filter=&#39;</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i <span class="token operator">*</span> <span class="token number">25</span><span class="token punctuation">)</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ol_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;//ol[@class=&quot;grid_view&quot;]/li&#39;</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> ol <span class="token keyword">in</span> ol_list<span class="token punctuation">:</span>
            item <span class="token operator">=</span> ScrapyDemoItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># extract_first() 提取第一个元素</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;title&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;hd&quot;]/a/span[1]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;rating&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;bd&quot;]/div/span[2]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;quote&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;bd&quot;]//p[@class=&quot;quote&quot;]/span/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&#39;__main__&#39;</span><span class="token punctuation">:</span>
    cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;scrapy crawl example --nolog&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="数据存储" tabindex="-1"><a class="header-anchor" href="#数据存储" aria-hidden="true">#</a> 数据存储</h2><h3 id="scrapy-pipeline-的作用" tabindex="-1"><a class="header-anchor" href="#scrapy-pipeline-的作用" aria-hidden="true">#</a> <strong>Scrapy Pipeline 的作用</strong></h3><ol><li><strong>数据清洗和验证</strong>：你可以在 pipeline 中编写代码来清洗和验证数据。例如，去除空白字符、处理缺失值、验证数据格式等；</li><li><strong>去重</strong>：可以检查和去除重复的数据项，确保最终的数据集是唯一的；</li><li><strong>存储</strong>：将处理过的数据存储到不同的存储后端，如数据库（MySQL、MongoDB）；</li><li><strong>进一步处理</strong>：执行复杂的转换、聚合等操作，以便在存储之前对数据进行进一步处理。</li></ol><h3 id="编写-pipeline" tabindex="-1"><a class="header-anchor" href="#编写-pipeline" aria-hidden="true">#</a> <strong>编写 Pipeline</strong></h3><p>这里我们使用 mysql 进行数据保存：</p>`,6),O={href:"http://pipeline.py",target:"_blank",rel:"noopener noreferrer"},U=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> pymysql
<span class="token keyword">from</span> itemadapter <span class="token keyword">import</span> ItemAdapter
<span class="token keyword">class</span> <span class="token class-name">MysqlPipeline</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>connection <span class="token operator">=</span> pymysql<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>
            user<span class="token operator">=</span><span class="token string">&#39;root&#39;</span><span class="token punctuation">,</span>  <span class="token comment"># 换上你自己的账密和数据库 </span>
            password<span class="token operator">=</span><span class="token string">&#39;root&#39;</span><span class="token punctuation">,</span> 
            db<span class="token operator">=</span><span class="token string">&#39;scrapy_demo&#39;</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cursor <span class="token operator">=</span> self<span class="token punctuation">.</span>connection<span class="token punctuation">.</span>cursor<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>create_table<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">create_table</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        table <span class="token operator">=</span> <span class="token triple-quoted-string string">&quot;&quot;&quot;
        CREATE TABLE IF NOT EXISTS douban (
            id INT AUTO_INCREMENT PRIMARY KEY,
            title VARCHAR(255) NOT NULL,
            rating FLOAT NOT NULL,
            quote TEXT
        )CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
        &quot;&quot;&quot;</span>
        self<span class="token punctuation">.</span>cursor<span class="token punctuation">.</span>execute<span class="token punctuation">(</span>table<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>connection<span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>cursor<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;INSERT INTO douban(id,title, rating, quote) VALUES (%s,%s, %s, %s)&quot;</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token string">&#39;title&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token string">&#39;rating&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token string">&#39;quote&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>connection<span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">except</span> pymysql<span class="token punctuation">.</span>MySQLError <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            spider<span class="token punctuation">.</span>logger<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f&quot;Error saving item: </span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">&quot;</span></span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item
    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>cursor<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>connection<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),z={href:"http://settings.py",target:"_blank",rel:"noopener noreferrer"},C=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">&quot;scrapy_demo.pipelines.MysqlPipeline&quot;</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>  <span class="token comment"># 放开Item </span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>配置好后，运行 example 就能看到我们的数据被正确入库了。</p><p>数据不止能存储 mysql，还存储到 mongo、csv 等等，感兴趣的小伙伴可以查看官方文档，有很详细的教程。</p><h2 id="scrapy-中间件" tabindex="-1"><a class="header-anchor" href="#scrapy-中间件" aria-hidden="true">#</a> scrapy 中间件</h2><h3 id="scrapy-中间件的分类和作用" tabindex="-1"><a class="header-anchor" href="#scrapy-中间件的分类和作用" aria-hidden="true">#</a> <strong>scrapy 中间件的分类和作用</strong></h3><p>根据 scrapy 运行流程中所在位置不同分为：</p><ol><li>下载中间件；</li><li>爬虫中间件。</li></ol><p>Scrapy 中间件（middlewares）的作用是处理 Scrapy 请求和响应的钩子（hook），允许你在它们被 Scrapy 引擎处理前或处理后对它们进行处理和修改。中间件为用户提供了一种方式，可以在请求和响应的不同阶段插入自定义逻辑。</p><p>一般我们常用的是下载中间件，所以下面我们用下载中间件来说明用法。</p>`,9),F={href:"http://middlewares.py",target:"_blank",rel:"noopener noreferrer"},H=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>Downloader Middlewares默认的方法：

<span class="token operator">-</span> process_request<span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span>：
  <span class="token operator">-</span> 当每个request通过下载中间件时，该方法被调用。
  <span class="token operator">-</span> 返回<span class="token boolean">None</span>值：继续请求
  <span class="token operator">-</span> 返回Response对象：不再请求，把response返回给引擎
  <span class="token operator">-</span> 返回Request对象：把request对象交给调度器进行后续的请求
<span class="token operator">-</span> process_response<span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span>：
  <span class="token operator">-</span> 当下载器完成http请求，传递响应给引擎的时候调用
  <span class="token operator">-</span> 返回Resposne：交给process_response来处理
  <span class="token operator">-</span> 返回Request对象：交给调取器继续请求
<span class="token operator">-</span> from_crawler<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token operator">-</span> 类似于init初始化方法<span class="token punctuation">,</span>只不过这里使用的<span class="token builtin">classmethod</span>类方法
  <span class="token operator">-</span> 可以直接crawler<span class="token punctuation">.</span>settings获得参数，也可以搭配信号使用

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="自定义随机-ua" tabindex="-1"><a class="header-anchor" href="#自定义随机-ua" aria-hidden="true">#</a> <strong>自定义随机 ua</strong></h3><p>我们借助 feapder 给我们封装好的 ua 来进行测试:</p>`,3),B={href:"http://middlewares.py",target:"_blank",rel:"noopener noreferrer"},V=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> feapder<span class="token punctuation">.</span>network <span class="token keyword">import</span> user_agent
<span class="token keyword">class</span> <span class="token class-name">ScrapyDemoDownloaderMiddleware</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        request<span class="token punctuation">.</span>headers<span class="token punctuation">[</span><span class="token string">&#39;User-Agent&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> user_agent<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),W={href:"http://settings.py",target:"_blank",rel:"noopener noreferrer"},j=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>DOWNLOADER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">&quot;scrapy_demo.middlewares.ScrapyDemoDownloaderMiddleware&quot;</span><span class="token punctuation">:</span> <span class="token number">543</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>  <span class="token comment"># 放开下载中间件</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),X={href:"http://example.py",target:"_blank",rel:"noopener noreferrer"},G=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline

<span class="token keyword">class</span> <span class="token class-name">ExampleSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&quot;example&quot;</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">&quot;https://movie.douban.com/top250&quot;</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>request<span class="token punctuation">.</span>headers<span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&#39;__main__&#39;</span><span class="token punctuation">:</span>
    cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;scrapy crawl example --nolog&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以发现每次输出的 ua 都不一样。</p><h3 id="自定义代理" tabindex="-1"><a class="header-anchor" href="#自定义代理" aria-hidden="true">#</a> <strong>自定义代理</strong></h3><p>通过 Request 对象的 mata 参数来设置代理，这里以本地的 7890 端口为例：</p>`,4),K={href:"http://middlewares.py",target:"_blank",rel:"noopener noreferrer"},Q=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        request<span class="token punctuation">.</span>headers<span class="token punctuation">[</span><span class="token string">&#39;User-Agent&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> user_agent<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
        request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">&#39;proxy&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">&quot;http://127.0.0.1:7890&quot;</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="中间件权重" tabindex="-1"><a class="header-anchor" href="#中间件权重" aria-hidden="true">#</a> <strong>中间件权重</strong></h3><p>当涉及到多个中间件的时候，请求时数字越小权重越高，越先执行，响应时数字越大越先执行。这里我们可以借助 scrapy 流程图来理解，谁离 scrapy engine 引擎越近，表明权重越高。</p><p>这里我们创建两个类来测试一下：</p>`,4),Y={href:"http://middlewares.py",target:"_blank",rel:"noopener noreferrer"},J=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">OneMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;one 请求&#39;</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_response</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;one 响应&#39;</span><span class="token punctuation">)</span>
        <span class="token comment"># return None</span>


<span class="token keyword">class</span> <span class="token class-name">TwoMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;two 请求&#39;</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_response</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&#39;two 响应&#39;</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> response
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),Z={href:"http://settings.py",target:"_blank",rel:"noopener noreferrer"},$=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>DOWNLOADER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">&quot;scrapy_demo.middlewares.OneMiddleware&quot;</span><span class="token punctuation">:</span> <span class="token number">543</span><span class="token punctuation">,</span>
   <span class="token string">&quot;scrapy_demo.middlewares.TwoMiddleware&quot;</span><span class="token punctuation">:</span> <span class="token number">544</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,1),nn={href:"http://example.py",target:"_blank",rel:"noopener noreferrer"},sn=e('<figure><img src="'+y+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><h2 id="scrapy-redis-组件" tabindex="-1"><a class="header-anchor" href="#scrapy-redis-组件" aria-hidden="true">#</a> scrapy-redis 组件</h2><p>Scrapy-Redis 是 Scrapy 的一个扩展，允许你使用 Redis 作为爬虫队列，并共享爬虫状态：</p><figure><img src="'+h+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>安装：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>pip install scrapy<span class="token operator">-</span>redis
<span class="token comment"># 注意：这里 scrapy 版本需要替换成 2.9.0 版本或者 2.0.0 以下，不然会报错：</span>
TypeError<span class="token punctuation">:</span> crawl<span class="token punctuation">(</span><span class="token punctuation">)</span> got an unexpected keyword argument <span class="token string">&#39;spider&#39;</span>
<span class="token comment"># 因为新版本已经不支持了。</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>然后新建 一个 redis_demo 爬虫</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>scrapy genspider redis_demo  redis_demo.com
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="配置-scrapy-redis" tabindex="-1"><a class="header-anchor" href="#配置-scrapy-redis" aria-hidden="true">#</a> <strong>配置 scrapy-redis</strong></h3>`,9),an={href:"http://settings.py",target:"_blank",rel:"noopener noreferrer"},tn=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 加入下面代码</span>
<span class="token comment"># 设置 Redis 主机和端口</span>
REDIS_URL <span class="token operator">=</span> <span class="token string">&#39;redis://127.0.0.1:6379/0&#39;</span>
<span class="token comment"># 使用 Scrapy-Redis 的调度器</span>
SCHEDULER <span class="token operator">=</span> <span class="token string">&quot;scrapy_redis.scheduler.Scheduler&quot;</span>

<span class="token comment"># 使用 Scrapy-Redis 的去重器</span>
DUPEFILTER_CLASS <span class="token operator">=</span> <span class="token string">&quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;</span>
 
<span class="token comment"># 开启 redis 管道</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">&quot;scrapy_redis.pipelines.RedisPipeline&quot;</span><span class="token punctuation">:</span> <span class="token number">301</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>redis_demo.py</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>
<span class="token keyword">from</span> scrapy_redis<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> RedisSpider
<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline

<span class="token comment"># 继承 scrapy——redis 类，实现分布式</span>
<span class="token keyword">class</span> <span class="token class-name">RedisDemoSpider</span><span class="token punctuation">(</span>RedisSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">&quot;redis_demo&quot;</span>
    redis_key <span class="token operator">=</span> <span class="token string">&quot;redis_demo:start_urls&quot;</span>  <span class="token comment"># redis key</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ol_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;//ol[@class=&quot;grid_view&quot;]/li&#39;</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> ol <span class="token keyword">in</span> ol_list<span class="token punctuation">:</span>
            item <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
            <span class="token comment"># extract_first() 提取第一个元素</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;title&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;hd&quot;]/a/span[1]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;rating&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;bd&quot;]/div/span[2]/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">&#39;quote&#39;</span><span class="token punctuation">]</span> <span class="token operator">=</span> ol<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">&#39;.//div[@class=&quot;bd&quot;]//p[@class=&quot;quote&quot;]/span/text()&#39;</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>
            <span class="token keyword">yield</span> item


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">&#39;__main__&#39;</span><span class="token punctuation">:</span>
    cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">&quot;scrapy crawl redis_demo&quot;</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>运行后会发现已经在监听端口了：</p><figure><img src="`+f+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>这时我们新建一个 demo 文件：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> redis

r <span class="token operator">=</span> redis<span class="token punctuation">.</span>Redis<span class="token punctuation">(</span>db<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
r<span class="token punctuation">.</span>lpush<span class="token punctuation">(</span><span class="token string">&#39;redis_demo:start_urls&#39;</span><span class="token punctuation">,</span><span class="token string">&quot;https://movie.douban.com/top250&quot;</span><span class="token punctuation">)</span>
<span class="token comment">#r.lpush(&#39;redis_demo:start_urls&#39;,&quot;https://movie.douban.com/top250?start=25&amp;filter=&quot;)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,7),en={href:"http://demo.py",target:"_blank",rel:"noopener noreferrer"},pn=n("figure",null,[n("img",{src:_,alt:"",tabindex:"0",loading:"lazy"}),n("figcaption")],-1),on=n("p",null,"我们打开 redis 可视化工具进行查看：",-1),cn=n("figure",null,[n("img",{src:x,alt:"",tabindex:"0",loading:"lazy"}),n("figcaption")],-1),ln=n("p",null,"但是现在当我们每次跑一个地址的时候，原来的数据就没有了，要想解决这个问题，我们就得运用到 scrapy-redis 的持久化存储了。",-1),un=n("h3",{id:"redis-持久化存储",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#redis-持久化存储","aria-hidden":"true"},"#"),s(),n("strong",null,"redis 持久化存储")],-1),rn=n("p",null,"Scrapy-Redis 默认会在爬取全部完成后清空爬取队列和去重指纹集合。初始第一个网址一定会进行请求，后面的重复方式不会进行请求。",-1),dn={href:"http://settings.py",target:"_blank",rel:"noopener noreferrer"},kn=e(`<div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>SCHEDULER_PERSIST <span class="token operator">=</span> <span class="token boolean">True</span>   <span class="token comment">#如果需要持久化爬取状态，可以开启</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,1),mn={href:"http://demo.py",target:"_blank",rel:"noopener noreferrer"},vn=e('<figure><img src="'+q+`" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>至此，完成了持久化存储。</p><h3 id="redis-分布式" tabindex="-1"><a class="header-anchor" href="#redis-分布式" aria-hidden="true">#</a> <strong>redis 分布式</strong></h3><p>要想在多台电脑跑同一个程序，只需要把其它电脑的 redis 连接到一台就行：</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># settings.py</span>
<span class="token comment"># 设置 Redis 主机和端口</span>
REDIS_URL <span class="token operator">=</span> <span class="token string">&#39;这里写你的远程电脑ip地址&#39;</span>
<span class="token comment"># 使用 Scrapy-Redis 的调度器</span>
SCHEDULER <span class="token operator">=</span> <span class="token string">&quot;scrapy_redis.scheduler.Scheduler&quot;</span>

<span class="token comment"># 使用 Scrapy-Redis 的去重器</span>
DUPEFILTER_CLASS <span class="token operator">=</span> <span class="token string">&quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;</span>

<span class="token comment"># 开启 redis 管道</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">&quot;scrapy_redis.pipelines.RedisPipeline&quot;</span><span class="token punctuation">:</span> <span class="token number">301</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>喜欢这篇文章的话，可以关注一下我的公众号『<strong>海哥python</strong>』</p></blockquote>`,6);function bn(gn,yn){const a=o("ExternalLinkIcon");return i(),c("div",null,[S,n("p",null,[s("修改 "),n("a",E,[s("example.py"),t(a)]),s(" 文件：")]),R,n("p",null,[s("在 "),n("a",T,[s("setting.py"),t(a)]),s(" 增加请求头、修改 robots 协议：")]),I,n("p",null,[s("修改 "),n("a",L,[s("example.py"),t(a)]),s(" 文件代码：")]),D,n("p",null,[n("a",P,[s("item.py"),t(a)]),s(" 编写如下：")]),A,n("p",null,[s("在 "),n("a",N,[s("example.py"),t(a)]),s(" 导入我们需要使用的 item 类，这里我们就用默认的 ScrapyDemoItem 类：")]),M,n("ul",null,[n("li",null,[n("a",O,[s("pipeline.py"),t(a)])])]),U,n("ul",null,[n("li",null,[n("a",z,[s("settings.py"),t(a)])])]),C,n("ul",null,[n("li",null,[n("a",F,[s("middlewares.py"),t(a)])])]),H,n("ul",null,[n("li",null,[n("a",B,[s("middlewares.py"),t(a)])])]),V,n("ul",null,[n("li",null,[n("a",W,[s("settings.py"),t(a)])])]),j,n("ul",null,[n("li",null,[n("a",X,[s("example.py"),t(a)])])]),G,n("ul",null,[n("li",null,[n("a",K,[s("middlewares.py"),t(a)])])]),Q,n("ul",null,[n("li",null,[n("a",Y,[s("middlewares.py"),t(a)])])]),J,n("ul",null,[n("li",null,[n("a",Z,[s("settings.py"),t(a)])])]),$,n("p",null,[s("运行 "),n("a",nn,[s("example.py"),t(a)]),s(" 输出如下结果：")]),sn,n("ul",null,[n("li",null,[n("a",an,[s("settings.py"),t(a)])])]),tn,n("p",null,[s("然后运行这个 "),n("a",en,[s("demo.py"),t(a)]),s(" 文件，会发现数据已经成功入库了：")]),pn,on,cn,ln,un,rn,n("p",null,[s("如果不想自动清空爬取队列和去重指纹集合，我们在 "),n("a",dn,[s("settings.py"),t(a)]),s(" 增加如下配置：")]),kn,n("p",null,[s("再次运行 redis_demo.py，然后运行两次 "),n("a",mn,[s("demo.py"),t(a)]),s(" 文件可以测试一下：")]),vn])}const _n=p(w,[["render",bn],["__file","17.Scrapy框架.html.vue"]]);export{_n as default};
