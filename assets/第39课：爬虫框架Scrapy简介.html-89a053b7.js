const e=JSON.parse('{"key":"v-7f0a7f13","path":"/docs/python/python%E5%9F%BA%E7%A1%80/%E7%AC%AC39%E8%AF%BE%EF%BC%9A%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy%E7%AE%80%E4%BB%8B.html","title":"第39课：爬虫框架Scrapy简介","lang":"zh-CN","frontmatter":{"title":"第39课：爬虫框架Scrapy简介","icon":"book","order":39,"index":true,"article":false,"description":"第39课：爬虫框架Scrapy简介 当你写了很多个爬虫程序之后，你会发现每次写爬虫程序时，都需要将页面获取、页面解析、爬虫调度、异常处理、反爬应对这些代码从头至尾实现一遍，这里面有很多工作其实都是简单乏味的重复劳动。那么，有没有什么办法可以提升我们编写爬虫代码的效率呢？答案是肯定的，那就是利用爬虫框架，而在所有的爬虫框架中，Scrapy 应该是最流行、...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/docs/python/python%E5%9F%BA%E7%A1%80/%E7%AC%AC39%E8%AF%BE%EF%BC%9A%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6Scrapy%E7%AE%80%E4%BB%8B.html"}],["meta",{"property":"og:site_name","content":"暴走の海鸽"}],["meta",{"property":"og:title","content":"第39课：爬虫框架Scrapy简介"}],["meta",{"property":"og:description","content":"第39课：爬虫框架Scrapy简介 当你写了很多个爬虫程序之后，你会发现每次写爬虫程序时，都需要将页面获取、页面解析、爬虫调度、异常处理、反爬应对这些代码从头至尾实现一遍，这里面有很多工作其实都是简单乏味的重复劳动。那么，有没有什么办法可以提升我们编写爬虫代码的效率呢？答案是肯定的，那就是利用爬虫框架，而在所有的爬虫框架中，Scrapy 应该是最流行、..."}],["meta",{"property":"og:type","content":"website"}],["meta",{"property":"og:image","content":"https://vuepress-theme-hope-docs-demo.netlify.app/"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"name":"twitter:card","content":"summary_large_image"}],["meta",{"name":"twitter:image:alt","content":"第39课：爬虫框架Scrapy简介"}],["meta",{"property":"article:author","content":"Mr.暴走の海鸽"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"WebPage\\",\\"name\\":\\"第39课：爬虫框架Scrapy简介\\",\\"description\\":\\"第39课：爬虫框架Scrapy简介 当你写了很多个爬虫程序之后，你会发现每次写爬虫程序时，都需要将页面获取、页面解析、爬虫调度、异常处理、反爬应对这些代码从头至尾实现一遍，这里面有很多工作其实都是简单乏味的重复劳动。那么，有没有什么办法可以提升我们编写爬虫代码的效率呢？答案是肯定的，那就是利用爬虫框架，而在所有的爬虫框架中，Scrapy 应该是最流行、...\\"}"]]},"headers":[{"level":2,"title":"第39课：爬虫框架Scrapy简介","slug":"第39课-爬虫框架scrapy简介","link":"#第39课-爬虫框架scrapy简介","children":[{"level":3,"title":"Scrapy 概述","slug":"scrapy-概述","link":"#scrapy-概述","children":[]},{"level":3,"title":"安装和使用Scrapy","slug":"安装和使用scrapy","link":"#安装和使用scrapy","children":[]}]}],"git":{"createdTime":null,"updatedTime":null,"contributors":[]},"readingTime":{"minutes":8.01,"words":2404},"filePathRelative":"docs/python/python基础/第39课：爬虫框架Scrapy简介.md","excerpt":"","autoDesc":true}');export{e as data};
