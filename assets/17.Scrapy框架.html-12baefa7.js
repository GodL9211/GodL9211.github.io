const e=JSON.parse('{"key":"v-66edf074","path":"/docs/python/%E7%88%AC%E8%99%AB/17.Scrapy%E6%A1%86%E6%9E%B6.html","title":"17.Scrapy框架","lang":"zh-CN","frontmatter":{"title":"17.Scrapy框架","icon":"book","order":17,"index":true,"article":false,"author":"k哥爬虫","description":"前言 大家好，我是海鸽。 Scrapy 简介 Scrapy 是一个用于爬取网站并提取结构化数据的强大且灵活的开源框架。它提供了简单易用的工具和组件，使开发者能够定义爬虫、调度请求、处理响应并存储提取的数据。Scrapy 具有高效的异步处理能力，支持分布式爬取，通过其中间件和扩展机制可以方便地定制和扩展功能，广泛应用于数据挖掘、信息聚合和自动化测试等领域...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/docs/python/%E7%88%AC%E8%99%AB/17.Scrapy%E6%A1%86%E6%9E%B6.html"}],["meta",{"property":"og:site_name","content":"暴走の海鸽"}],["meta",{"property":"og:title","content":"17.Scrapy框架"}],["meta",{"property":"og:description","content":"前言 大家好，我是海鸽。 Scrapy 简介 Scrapy 是一个用于爬取网站并提取结构化数据的强大且灵活的开源框架。它提供了简单易用的工具和组件，使开发者能够定义爬虫、调度请求、处理响应并存储提取的数据。Scrapy 具有高效的异步处理能力，支持分布式爬取，通过其中间件和扩展机制可以方便地定制和扩展功能，广泛应用于数据挖掘、信息聚合和自动化测试等领域..."}],["meta",{"property":"og:type","content":"website"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-07-17T10:24:44.000Z"}],["meta",{"property":"article:author","content":"k哥爬虫"}],["meta",{"property":"article:modified_time","content":"2024-07-17T10:24:44.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"WebPage\\",\\"name\\":\\"17.Scrapy框架\\",\\"description\\":\\"前言 大家好，我是海鸽。 Scrapy 简介 Scrapy 是一个用于爬取网站并提取结构化数据的强大且灵活的开源框架。它提供了简单易用的工具和组件，使开发者能够定义爬虫、调度请求、处理响应并存储提取的数据。Scrapy 具有高效的异步处理能力，支持分布式爬取，通过其中间件和扩展机制可以方便地定制和扩展功能，广泛应用于数据挖掘、信息聚合和自动化测试等领域...\\"}"]]},"headers":[{"level":2,"title":"前言","slug":"前言","link":"#前言","children":[]},{"level":2,"title":"Scrapy 简介","slug":"scrapy-简介","link":"#scrapy-简介","children":[]},{"level":2,"title":"安装 Scrapy","slug":"安装-scrapy","link":"#安装-scrapy","children":[]},{"level":2,"title":"新建 Scrapy 项目","slug":"新建-scrapy-项目","link":"#新建-scrapy-项目","children":[]},{"level":2,"title":"使用 Scrapy","slug":"使用-scrapy","link":"#使用-scrapy","children":[{"level":3,"title":"Scrapy 运行项目的两种方式","slug":"scrapy-运行项目的两种方式","link":"#scrapy-运行项目的两种方式","children":[]},{"level":3,"title":"数据翻页抓取","slug":"数据翻页抓取","link":"#数据翻页抓取","children":[]}]},{"level":2,"title":"数据定义","slug":"数据定义","link":"#数据定义","children":[{"level":3,"title":"Scrapy Item 的作用","slug":"scrapy-item-的作用","link":"#scrapy-item-的作用","children":[]},{"level":3,"title":"定义 item","slug":"定义-item","link":"#定义-item","children":[]},{"level":3,"title":"使用 item","slug":"使用-item","link":"#使用-item","children":[]}]},{"level":2,"title":"数据存储","slug":"数据存储","link":"#数据存储","children":[{"level":3,"title":"Scrapy Pipeline 的作用","slug":"scrapy-pipeline-的作用","link":"#scrapy-pipeline-的作用","children":[]},{"level":3,"title":"编写 Pipeline","slug":"编写-pipeline","link":"#编写-pipeline","children":[]}]},{"level":2,"title":"scrapy 中间件","slug":"scrapy-中间件","link":"#scrapy-中间件","children":[{"level":3,"title":"scrapy 中间件的分类和作用","slug":"scrapy-中间件的分类和作用","link":"#scrapy-中间件的分类和作用","children":[]},{"level":3,"title":"自定义随机 ua","slug":"自定义随机-ua","link":"#自定义随机-ua","children":[]},{"level":3,"title":"自定义代理","slug":"自定义代理","link":"#自定义代理","children":[]},{"level":3,"title":"中间件权重","slug":"中间件权重","link":"#中间件权重","children":[]}]},{"level":2,"title":"scrapy-redis 组件","slug":"scrapy-redis-组件","link":"#scrapy-redis-组件","children":[{"level":3,"title":"配置 scrapy-redis","slug":"配置-scrapy-redis","link":"#配置-scrapy-redis","children":[]},{"level":3,"title":"redis 持久化存储","slug":"redis-持久化存储","link":"#redis-持久化存储","children":[]},{"level":3,"title":"redis 分布式","slug":"redis-分布式","link":"#redis-分布式","children":[]}]}],"git":{"createdTime":1721211884000,"updatedTime":1721211884000,"contributors":[{"name":"lianhaifeng","email":"lianhaifeng@rongannetworks.com","commits":1}]},"readingTime":{"minutes":13.43,"words":4030},"filePathRelative":"docs/python/爬虫/17.Scrapy框架.md","localizedDate":"2024年7月17日","excerpt":"","autoDesc":true}');export{e as data};
